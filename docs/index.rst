.. obp documentation master file, created by
   sphinx-quickstart on Tue Jun 23 17:55:21 2020.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

Welcome to obp's documentation!
====================================

Open Bandit Dataset and Pipeline
=====================================

Overview
~~~~~~~~~~~~

*Open Bandit Pipeline (OBP)* is a Python 3.7+ offline bandit simulation toolkit.
The toolkit comes with the *Open Bandit Dataset* , a logged bandit feedback collected on a large-scale fashion e-commerce platform, `ZOZOTOWN <https://corp.zozo.com/en/service/>`_.
The purpose of the open data and library is to enable easy, realistic, and reproducible evaluation of bandit algorithms and off-policy evaluation (OPE).
OBP has a series of implementations of dataset preprocessing, bandit policy interfaces, offline bandit simulator, and standard OPE estimators.

Our open data and pipeline facilitate evaluation and comparison related to the following research topics.

* **Bandit Algorithms**: Our data include large-scale logged bandit feedback collected by the uniform random policy. Therefore, it enables the evaluation of new online bandit algorithms, including contextual and combinatorial algorithms, in a large real-world setting.


* **Off-Policy Evaluation**: We present implementations of behavior policies used when collecting datasets as a part of our pipeline. Our open data also contains logged bandit feedback data generated by multiple behavior policies. Therefore, it enables the evaluation of off-policy evaluation with ground-truth for the performance of counterfactual policies.

This website contains pages with example analyses to help demonstrate the usage of this library.
Additionally, it presents examples of conducting the evaluation of counterfactual bandit algorithms and off-policy evaluation.
The reference page contains the full reference documentation for the current functions of this toolkit.

Supported Algorithms and OPE Estimators
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Bandit Algorithms
----------------------

   * Context-free

      * Random
      * Epsilon Greedy
      * Bernoulli Thompson Sampling

   * Contextual

      * Logistic Epsilon Greedy
      * Logistic Thompson Sampling :cite:`Chapelle2011`
      * Logistic Upper Confidence Bound :cite:`Li2010` :cite:`Mahajan2012`

OPE Estimators
----------------------
   * Replay Method :cite:`Li2012`
   * Direct Method :cite:`Beygelzimer2009`
   * Inverse Probability Weighting :cite:`Precup2000` :cite:`Strehl2010`
   * Self-Normalized Inserse Probability Weighting :cite:`Swaminathan2015b`
   * Doubly Robust :cite:`Dudik2014`
   * Switch Estimator :cite:`Wang2016`
   * More Robust Doubly Robust :cite:`Farajtabar2018`
   * Double Machine Learning :cite:`Narita2020`

Licence
~~~~~~~~~~~~
Open Bandit Pipeline is released under Apache 2.0 license. Find out more about it at `LICENSE <https://github.com/st-tech/zr-obp/blob/master/LICENSE>`_.

Citation
~~~~~~~~~~~~
If you use this project in your work, please cite our paper below.

# TODO: add bibtex
@article{
}


.. toctree::
   :maxdepth: 3
   :caption: Introduction:

   about
   ope

.. toctree::
   :maxdepth: 3
   :caption: Getting Started:

   installation
   quickstart
   poc

.. toctree::
   :maxdepth: 3
   :caption: Package Reference:

   obp

.. toctree::
    :caption: Others:

    Github <https://github.com/st-tech/zr-obp>
    references



Indices and tables
==================

* :ref:`genindex`
* :ref:`modindex`
* :ref:`search`
