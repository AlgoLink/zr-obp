{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "from typing import Tuple, Optional, List, Union, Dict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/usaito/workspace/obp-temp')\n",
    "from estimator import InverseProbabilityWeighting, DirectMethod, DoublyRobust\n",
    "from train_regression_model import train_eval_lgbm\n",
    "from dataset import OBDWithContextSets\n",
    "from obp.simulator import BanditSimulator\n",
    "from obp.policy import Random, BernoulliTS\n",
    "from logistic_bandit import LogisticTS, LogisticUCB\n",
    "from obp.utils import estimate_confidence_interval_by_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('.').resolve().parents[1] / 'obd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "obd = OBDWithContextSets(behavior_policy='rand', campaign='men', context_set='1', data_path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = obd.split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dict_keys(['action', 'position', 'reward', 'pscore', 'X_policy', 'X_reg', 'X_user'])"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Regression Model for DM and DR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 2\n",
    "hyperparams = dict(max_iter=1000, learning_rate=0.01, min_samples_leaf=5, random_state=12345)\n",
    "regression_model_dict, performance_dict = train_eval_lgbm(\n",
    "    dataset=obd, n_splits=n_splits, hyperparams=hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.004857142857142857"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "train['reward'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model_results = dict()\n",
    "for metric, values in performance_dict.items():\n",
    "    regression_model_results[metric] = estimate_confidence_interval_by_bootstrap(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         mean     lower     upper\nauc  0.498990  0.404563  0.592834\nrce -0.020714 -0.042453  0.001352",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>lower</th>\n      <th>upper</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>auc</th>\n      <td>0.498990</td>\n      <td>0.404563</td>\n      <td>0.592834</td>\n    </tr>\n    <tr>\n      <th>rce</th>\n      <td>-0.020714</td>\n      <td>-0.042453</td>\n      <td>0.001352</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "pd.DataFrame(regression_model_results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5.1: Off-Policy Estimator Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = BanditSimulator()\n",
    "policy = BernoulliTS(n_actions=obd.n_actions, len_list=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 7000/7000 [00:00<00:00, 24987.07it/s]\n100%|██████████| 7000/7000 [00:00<00:00, 23705.34it/s]\n100%|██████████| 7000/7000 [00:00<00:00, 23127.72it/s]\n100%|██████████| 7000/7000 [00:00<00:00, 23777.56it/s]\n100%|██████████| 7000/7000 [00:00<00:00, 23665.84it/s]\n 29%|██▉       | 2043/7000 [00:00<00:00, 20424.27it/s]random_state=0\nDM: 0.21364\nIPW: 0.271429\nDR: 0.260185\n100%|██████████| 7000/7000 [00:00<00:00, 22526.94it/s]\n100%|██████████| 7000/7000 [00:00<00:00, 23007.47it/s]\n100%|██████████| 7000/7000 [00:00<00:00, 22799.52it/s]\n100%|██████████| 7000/7000 [00:00<00:00, 22492.25it/s]\n100%|██████████| 7000/7000 [00:00<00:00, 22743.75it/s]\nrandom_state=1\nDM: 0.758096\nIPW: 0.295238\nDR: 0.340446\n"
    }
   ],
   "source": [
    "n_splits = 2\n",
    "n_estimators = 5\n",
    "np.random.seed(12345)\n",
    "\n",
    "ope_results = {est: np.zeros(n_splits) for est in ['dm', 'ipw', 'dr']}\n",
    "for random_state in np.arange(n_splits):\n",
    "    ipw = InverseProbabilityWeighting()\n",
    "    dm = DirectMethod(regression_model=regression_model_dict[random_state])\n",
    "    dr = DoublyRobust(regression_model=regression_model_dict[random_state])\n",
    "    estimator_dict = dict(dm=dm, ipw=ipw, dr=dr)\n",
    "\n",
    "    train, test = obd.split_data(random_state=random_state)\n",
    "    reward_test = test['reward']\n",
    "\n",
    "    # bagging aggregation\n",
    "    ope_results_temp = {est: np.zeros(n_estimators) for est in estimator_dict}\n",
    "    for seed in np.arange(n_estimators):  # TODO: parallelization\n",
    "        # run a bandit algorithm on logged bandit feedback\n",
    "        boot_idx = np.random.choice(np.arange(obd.train_size), size=obd.train_size)\n",
    "        train_boot = {key: arr[boot_idx] for key, arr in train.items()}\n",
    "        simulation_log = sim.simulate(policy=policy, train=train_boot)\n",
    "        # off-policy evaluation by using the result of the simulation\n",
    "        for est_name, est in estimator_dict.items():\n",
    "            ope_results_temp[est_name][seed] = est.estimate(\n",
    "                simulation_log, train['X_user'], obd.X_action)\n",
    "        # initialize policy parameters\n",
    "        policy.initialize()\n",
    "\n",
    "    # print results of each train-test split\n",
    "    print(f'random_state={random_state}')\n",
    "    ground_truth = np.mean(reward_test)\n",
    "    for est_name, est in estimator_dict.items():\n",
    "        estimated_policy_value = np.mean(ope_results_temp[est_name])\n",
    "        relative_estimation_error_of_est = np.abs((estimated_policy_value - ground_truth) / ground_truth)\n",
    "        ope_results[est_name][random_state] = relative_estimation_error_of_est\n",
    "        print(f'{est_name.upper()}: {np.round(relative_estimation_error_of_est, 6)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'dm': array([0.21364029, 0.75809628]),\n 'ipw': array([0.27142857, 0.2952381 ]),\n 'dr': array([0.2601853 , 0.34044627])}"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "ope_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate confidence intervals by a nonparametric bootstrap method\n",
    "ope_results_with_ci = {est: dict() for est in estimator_dict}\n",
    "for est_name in estimator_dict.keys():\n",
    "    ope_results_with_ci[est_name] =\\\n",
    "        estimate_confidence_interval_by_bootstrap(samples=ope_results[est_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         mean     lower     upper\ndm   0.486467  0.213640  0.758096\nipw  0.283469  0.271429  0.295238\ndr   0.300147  0.260185  0.340446",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>lower</th>\n      <th>upper</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dm</th>\n      <td>0.486467</td>\n      <td>0.213640</td>\n      <td>0.758096</td>\n    </tr>\n    <tr>\n      <th>ipw</th>\n      <td>0.283469</td>\n      <td>0.271429</td>\n      <td>0.295238</td>\n    </tr>\n    <tr>\n      <th>dr</th>\n      <td>0.300147</td>\n      <td>0.260185</td>\n      <td>0.340446</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "pd.DataFrame(ope_results_with_ci).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   action  reward  position    pscore  selected_action  indicator\n0      33       0         2  0.029412                0          0\n1      15       0         1  0.029412               26          0\n2      21       0         3  0.029412                9          0\n3       8       0         2  0.029412                7          0\n4       4       0         2  0.029412               31          0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>action</th>\n      <th>reward</th>\n      <th>position</th>\n      <th>pscore</th>\n      <th>selected_action</th>\n      <th>indicator</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>33</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.029412</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.029412</td>\n      <td>26</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.029412</td>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.029412</td>\n      <td>7</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.029412</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "simulation_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5.2 Counterfactual Policy Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = BanditSimulator()\n",
    "policy = LogisticUCB(n_actions=obd.n_actions, len_list=3, dim=obd.dim_context, epsilon=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 7000/7000 [00:03<00:00, 2014.13it/s]\n100%|██████████| 7000/7000 [00:03<00:00, 2055.67it/s]\n100%|██████████| 7000/7000 [00:03<00:00, 1945.23it/s]\n100%|██████████| 7000/7000 [00:03<00:00, 2020.95it/s]\n100%|██████████| 7000/7000 [00:03<00:00, 2030.22it/s]\n100%|██████████| 7000/7000 [00:03<00:00, 2020.38it/s]\n100%|██████████| 7000/7000 [00:03<00:00, 1902.79it/s]\n100%|██████████| 7000/7000 [00:03<00:00, 1854.47it/s]\n100%|██████████| 7000/7000 [00:03<00:00, 1916.66it/s]\n100%|██████████| 7000/7000 [00:03<00:00, 1932.27it/s]\n100%|██████████| 7000/7000 [00:03<00:00, 2023.31it/s]\n100%|██████████| 7000/7000 [00:03<00:00, 1994.31it/s]\n100%|██████████| 7000/7000 [00:03<00:00, 2018.10it/s]\n100%|██████████| 7000/7000 [00:03<00:00, 2051.06it/s]\n100%|██████████| 7000/7000 [00:03<00:00, 2036.24it/s]\n=========================\nrandom_state=0\n-----\nDM: 1.294161\nIPW: 2.185714\nDR: 2.102411\n========================= \n\n"
    }
   ],
   "source": [
    "n_estimators = 15\n",
    "random_state = 0\n",
    "np.random.seed(12345)\n",
    "ipw = InverseProbabilityWeighting()\n",
    "dm = DirectMethod(regression_model=regression_model_dict[random_state])\n",
    "dr = DoublyRobust(regression_model=regression_model_dict[random_state])\n",
    "estimator_dict = dict(dm=dm, ipw=ipw, dr=dr)\n",
    "\n",
    "train, test = obd.split_data(random_state=random_state)\n",
    "reward_test = test['reward']\n",
    "ground_truth = np.mean(reward_test)\n",
    "\n",
    "# bagging aggregation\n",
    "ope_results = {est: np.zeros(n_estimators) for est in estimator_dict}\n",
    "relative_ope_results = {est: np.zeros(n_estimators) for est in estimator_dict}\n",
    "for seed in np.arange(n_estimators):  # TODO: parallelization\n",
    "    # run a bandit algorithm on logged bandit feedback\n",
    "    boot_idx = np.random.choice(np.arange(obd.train_size), size=obd.train_size)\n",
    "    train_boot = {key: arr[boot_idx] for key, arr in train.items()}\n",
    "    simulation_log = sim.simulate(policy=policy, train=train_boot)\n",
    "    # off-policy evaluation by using the result of the simulation\n",
    "    for est_name, est in estimator_dict.items():\n",
    "        estimated_policy_value =  est.estimate(simulation_log, train['X_user'], obd.X_action)\n",
    "        ope_results[est_name][seed] = estimated_policy_value / ground_truth\n",
    "    # initialize policy parameters\n",
    "    policy.initialize()\n",
    "\n",
    "# print results of each train-test split\n",
    "print('=' * 25)\n",
    "print(f'random_state={random_state}')\n",
    "print('-----')\n",
    "for est_name, est in estimator_dict.items():\n",
    "    relative_estimated_policy_value = np.mean(ope_results[est_name])\n",
    "    print(f'{est_name.upper()}: {np.round(relative_estimated_policy_value, 6)}')\n",
    "print('=' * 25, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, upper, lower = estimate_confidence_interval_by_bootstrap(ope_results['dr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         mean     upper     lower\nucb  2.105119  1.447319  2.727798",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>upper</th>\n      <th>lower</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ucb</th>\n      <td>2.105119</td>\n      <td>1.447319</td>\n      <td>2.727798</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "pd.DataFrame(dict(mean=mean, upper=upper, lower=lower), index=['ucb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitbaseconda517bce94c78346bf9ee896b8640c6d1e",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}